# ğŸ¥ Projeto ANS - Web Scraping + API + Frontend

Este projeto foi desenvolvido como parte de um desafio tÃ©cnico para uma vaga de estÃ¡gio. Ele automatiza a extraÃ§Ã£o de informaÃ§Ãµes pÃºblicas da ANS (AgÃªncia Nacional de SaÃºde Suplementar), armazena os dados em um banco de dados relacional, expÃµe esses dados via API e fornece uma interface frontend para consulta e visualizaÃ§Ã£o.

---

## ğŸ“ Estrutura do Projeto

```

â”œâ”€â”€ exercise_1/
â”‚   â”œâ”€â”€ web_scraping.py       # Web scraping dos PDFs da ANS
â”œâ”€â”€ exercise_2/
â”‚   â”œâ”€â”€ data_transforming.py  # ExtraÃ§Ã£o e transformaÃ§Ã£o de dados do PDF
â”œâ”€â”€ exercise_3/
â”‚   â”œâ”€â”€ 01_create_table_operadoras.sql           # CriaÃ§Ã£o da tabela operadoras
â”‚   â”œâ”€â”€ 02_create_table_demonstracoes_contabeis.sql  # CriaÃ§Ã£o da tabela contÃ¡bil
â”‚   â”œâ”€â”€ 03_insert_data_ans.sql                   # Popula tabela de operadoras
â”‚   â”œâ”€â”€ 04_insert_data_contabeis.sql             # Popula tabela contÃ¡bil
â”‚   â””â”€â”€ analytics_queries.sql                    # Consultas analÃ­ticas
â”œâ”€â”€ exercise_4/
â”‚   â”œâ”€â”€ backend/              # Backend estruturado (Flask)
â”‚   â”‚   â”œâ”€â”€ server.py            # Arquivo principal da API
â”‚   â”œâ”€â”€ frontend/             # Frontend em Vue.js
â”‚   â”‚   â”œâ”€â”€ src/              # CÃ³digo fonte Vue
â”‚   â””â”€â”€ postman/              # ColeÃ§Ã£o Postman
â”‚       â”œâ”€â”€ API Operadoras.postman_collection.json  # DocumentaÃ§Ã£o das rotas
â”œâ”€â”€ utils/                    # FunÃ§Ãµes utilitÃ¡rias (ex: compressToZip)
â”œâ”€â”€ data/                     # Arquivos CSV e PDFs processados
â””â”€â”€ docker-compose.yml        # ConfiguraÃ§Ã£o de containers
```

## ğŸ”§ Tecnologias Utilizadas

### Backend (Python + Flask)

- Flask + Flask-CORS
- SQLAlchemy
- pdfplumber
- BeautifulSoup
- MySQL
- Docker

### Frontend (Vue.js)

- Vue 3
- Axios
- TypeScript
- HTML/CSS
- Docker

### Infra

- Docker e Docker Compose
- VariÃ¡veis de ambiente com dotenv

---

## ğŸ“¦ Funcionalidades

### ğŸ—‚ Web Scraping

- Acessa o site da ANS e faz download automÃ¡tico dos anexos PDF
- Salva e comprime os arquivos localmente

### ğŸ“Š Processamento de Dados

- Extrai tabelas dos PDFs com `pdfplumber`
- Remove repetiÃ§Ãµes de cabeÃ§alhos
- Renomeia colunas para facilitar leitura
- Salva como CSV

### ğŸ–¥ API Flask

- Importa os dados para banco MySQL
- Disponibiliza endpoint `/search` com:
  - Filtro por nome fantasia, razÃ£o social ou CNPJ
  - PaginaÃ§Ã£o
- Endpoint `/health` e `/test-db` para testes

### ğŸ” Frontend (Vue.js)

- Interface de busca com campo dinÃ¢mico
- VisualizaÃ§Ã£o de operadoras em uma tabela
- PaginaÃ§Ã£o de resultados

## ğŸ Ambiente Virtual Python (venv)

Para garantir que todas as dependÃªncias do projeto sejam instaladas de forma isolada, recomenda-se o uso de um ambiente virtual (`venv`).

### ğŸ“Œ Verificando se o `venv` jÃ¡ estÃ¡ disponÃ­vel

Execute o comando abaixo no terminal:

```bash
python3 -m venv --help
```

Se vocÃª nÃ£o tiver o venv instalado, serÃ¡ necessÃ¡rio instalar o mÃ³dulo. Em sistemas baseados em Debian/Ubuntu, vocÃª pode fazer isso com:

```bash
sudo apt install python3-venv
```

### âœ… Criando e ativando o ambiente virtual

1. Crie o ambiente virtual (recomendado rodar na raiz do projeto):

```bash
python3 -m venv venv
```

2. Ative o ambiente virtual:

- Linux / macOS:

```bash
source venv/bin/activate
```

- Windows (CMD):

```bash
venv\Scripts\activate
```

- Windows (PowerShell):

```bash
.\venv\Scripts\Activate.ps1
```

### Instalando as dependÃªncias

Com o ambiente virtual ativado, instale todas as dependÃªncias do projeto com(recomendado rodar na raiz do projeto):

```bash
pip install -r requirements.txt
```

### Rodando os scripts do projeto

### PrÃ©-requisitos

- ExercÃ­cio 1
  Acesse o diretÃ³rio `exercise_1` e execute o seguinte comando:

```bash
cd exercise_1
python3 web_scraping.py
```

- ExercÃ­cio 2
  Acesse o diretÃ³rio `exercise_2` e execute o seguinte comando:

```bash
cd exercise_2
python3 data_transforming.py
```

- ExercÃ­cio 3

Acesse o diretÃ³rio exercise_3, em seguida abra o terminal no diretÃ³rio para rodar os arquivos `.sql`, vocÃª deve primeiro acessar o MySQL pelo terminal. Use o seguinte comando:

```bash
mysql -u seu_usuario -p
```

VocÃª serÃ¡ solicitado a digitar a senha do usuÃ¡rio. ApÃ³s o login, selecione o banco de dados onde deseja executar o script:

```bash
USE nome_do_banco_de_dados;
```

Execute os scripts na seguinte ordem:

```bash
SOURCE 01_create_table_operadoras.sql;                 -- CriaÃ§Ã£o da tabela de operadoras
SOURCE 02_create_table_demonstracoes_contabeis.sql;    -- CriaÃ§Ã£o da tabela de demonstraÃ§Ãµes contÃ¡beis
SOURCE 03_insert_data_ans.sql;                         -- PopulaÃ§Ã£o da tabela de operadoras
SOURCE 04_insert_data_contabeis.sql;                   -- PopulaÃ§Ã£o da tabela de demonstraÃ§Ãµes contÃ¡beis
SOURCE analytics_queries.sql;                          -- Consulta das maiores despesas

```

## ğŸš€ Como Rodar a API e o Frontend

### PrÃ©-requisitos

- Docker
- Docker Compose

### Passos

1. Crie um arquivo `.env` na raiz com as variÃ¡veis(Qualquer dÃºvida consulte o arquivo `.env.example`):

```env
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_HOST=db
DB_NAME=ans_database
```

2. Execute no terminal o seguinte comando:

```bash
docker-compose up -d
```

Esse comando irÃ¡ subir o container da aplicaÃ§Ã£o, tanto o backend, quanto o frontend e o banco de dados.

<strong>
âš ï¸ ObservaÃ§Ã£o: Como o banco de dados Ã© populado a partir de um arquivo CSV via API durante a inicializaÃ§Ã£o, Ã© necessÃ¡rio aguardar cerca de 2 minutos apÃ³s a subida dos containers para que os dados estejam totalmente disponÃ­veis nos endpoints.
</strong>

<br></br>

3.  Acesse a API:

```bash
    http://localhost:5000/
```

Consulte o arquivo API `Operadoras.postman_collection.json` no diretÃ³rio `/exercise_4/postman` para mais informaÃ§Ãµes sobre as rotas..

4. Acesse o Frontend:

```bash
    http://localhost:8080/
```

## Imagens do Projeto

![Buscar Operadoras](data/README_IMAGES/Screenshot%20from%202025-03-30%2013-33-51.png)
![Buscar Operadoras](data/README_IMAGES/Screenshot%20from%202025-03-30%2013-34-02.png)

## âœ… ConsideraÃ§Ãµes Finais

Este projeto demonstra a integraÃ§Ã£o entre web scraping, manipulaÃ§Ã£o de dados, API RESTful e interface web. Foi desenvolvido com foco em organizaÃ§Ã£o, clareza de cÃ³digo e separaÃ§Ã£o de responsabilidades entre backend, frontend e infraestrutura.
